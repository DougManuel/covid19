
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{A single-change-point model}
\setcounter{theorem}{0}
\setcounter{equation}{0}

%\cite{vanDerVaart1996}
%\cite{Kosorok2008}

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

Consider the data set \,\texttt{coal}\, available in the R package \,\texttt{boot}:
\begin{center}
\texttt{https://stat.ethz.ch/R-manual/R-devel/library/boot/html/coal.html}
\end{center}
which was first published in:
\begin{center}
\begin{minipage}{5in}
A Note on the Intervals Between Coal-Mining Disasters \\
Author(s): R. G. Jarrett \\
Source: Biometrika, Vol. 66, No. 1 (Apr., 1979), pp. 191-193 \\
Published by: Oxford University Press on behalf of Biometrika Trust \\
Stable URL: \texttt{https://www.jstor.org/stable/2335266}
\end{minipage}
\end{center}

\vskip 0.5cm
\noindent
The \,\texttt{coal}\, data frame has 191 rows and a single numeric column (with column name ``date''),
containing the dates of occurrence (in years, with dates represented as digits after the decimal point)
of the 191 explosions in coal mines in the United Kingdom which:
\begin{itemize}
\item
	occurred between March 15, 1851 and March 22 1962, and
\item
	resulted in 10 or more fatalities.
\end{itemize}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\noindent
\textbf{Modeling problem:}
\begin{itemize}
\item
	Question:
	\vskip 0.05cm
	Was there a change in the underlying rate of occurrence of coal mine explosions
	between March 15, 1851 and March 22 1962?

\item
	Approach:
	\vskip 0.05cm
	\begin{itemize}
	\item
		Transform raw data into a vector of annual counts of coal mine explosions.
	\item
		Fit a hierarchical single change-point model to the resulting transformed data.
	\end{itemize}

\end{itemize}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\noindent
\textbf{Observed data:}
\begin{itemize}
\item
	The observed data consist of a vector of counts:
	\begin{equation*}
	D \;\; = \;\; (D_{1}, D_{2}, \ldots , D_{T}) \;\; \in \;\; \left(\N\cup\{\,0\,\}\right)^{T}\,,
	\end{equation*}
	where
	$D_{t}$ represents the number of coal mine explosions that occurred during the $t$-th year,
	for $t = 1, 2, \ldots, T$.
	The yearly coal mine explosion counts are illustrated in the following figure:
	\begin{center}
	\includegraphics[width=6.5in]{graphics/coal-mine-explosion-count-by-year.png}
	\end{center}
	
\end{itemize}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\noindent
\textbf{Model:}
\begin{itemize}
\item
	User-prescribed (fixed) hyperparameters:
	\begin{equation*}
	r_{e}\,,\, r_{l} \; \in \; (1,\infty)\,,
	\quad\quad
	T \; \in \; \N
	\end{equation*}
\item
	Parameters (to be estimated) and their prior distributions:
	\begin{equation*}
	R_{e} \;\sim\; \textnormal{Exponential}(\,r_{e}\,)\,,
	\quad\quad
	R_{l} \;\sim\; \textnormal{Exponential}(\,r_{l}\,)\,,
	\quad\quad
	S \;\sim\; \textnormal{Uniform}\!\left(\,\{\overset{{\color{white}.}}{1},2,\ldots,T\}\,\right)
	\end{equation*}
	These three parameters are assumed to be independent of each other.
\item
	Conditional likelihood of observed data:
	\begin{equation*}
	D_{t}
	\;\; \sim \;\;
		\left\{\begin{array}{ccc}
		\textnormal{Poisson}(\,r_{e}\,)\,, & \textnormal{if \,$t < S$}
		\\
		\overset{{\color{white}1}}{\textnormal{Poisson}(\,r_{l}\,)}\,, & \textnormal{if \,$t \geq S$}
		\end{array}\right.,
	\quad\;\;
	t = 1, 2, \ldots, T
	\end{equation*}
\end{itemize}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\noindent
\textbf{Full joint probability distribution:}
\begin{eqnarray*}
P\!\left(\,D,S,R_{e},R_{l}\,\right)
& = &
	P\!\left(\,D \;\vert\, S,R_{e},R_{l}\,\right)
	\cdot
	P\!\left(\,S,R_{e},R_{l}\,\right)
\;\; = \;\;
	P\!\left(\,D \;\vert\, S,R_{e},R_{l}\,\right)
	\cdot
	P\!\left(\,S\,\right)
	\cdot
	P\!\left(\,R_{e}\,\right)
	\cdot
	P\!\left(\,R_{l}\,\right)
\\
& = &
	\left(\;
		\overset{T}{\underset{t=1}{\prod}}\,
		P\!\left(\,D_{t} \;\vert\, S,R_{e},R_{l}\,\right)
		\right)
	\times\,
	P\!\left(\,S\,\right)
	\cdot
	P\!\left(\,R_{e}\,\right)
	\cdot
	P\!\left(\,R_{l}\,\right)
\end{eqnarray*}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 1.0cm
\noindent
\begin{center}
\textbf{\large Marginal conditional probability distribution to be coded in \texttt{Stan}}
\end{center}
\vskip 0.3cm
\noindent
Since \texttt{Stan} does NOT support categorical latent variables,
the full joint probability distribution above cannot be implemented in \texttt{Stan}
(due to the presence of the discrete parameter $S \sim \textnormal{Uniform}\!\left(\,\{1,2,\ldots,T\}\,\right)$).
In other to perform inference with \texttt{Stan} involving categorical latent variables,
we implement instead the {\color{red}marginal probability}
\begin{equation*}
P\!\left(\,D,R_{e},R_{l}\,\right)
\;\; = \;\;
	\overset{T}{\underset{s=1}{\sum}}\;
	P\!\left(\,D,S=s,R_{e},R_{l}\,\right),
\end{equation*}
marginalizing out all categorical latent variables.

\vskip 0.5cm
\begin{proposition}
\mbox{}
\vskip 0.2cm
\noindent
The natural logarithm of the marginal conditional probability
\,$P\!\left(\,D\;\vert\,R_{e},R_{l}\,\right)$\,
can expressed as follows:
\begin{eqnarray*}
&&
	\underset{{\color{white}}}{\log P\!\left(\,D \;\vert\, R_{e},R_{l}\,\right)}
\\
&=&
	\log\left\{\;
	\overset{T}{\underset{s=1}{\sum}}\;
	\exp\left[\;
		\log P\!\left(\,S=s\,\right)
		\, + \,
		\overset{T}{\underset{t=1}{\sum}}\,
		\log P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
		\,\right]
	\,\right\}
\\
&=&
	\log\left\{\;
	\overset{T}{\underset{s=1}{\sum}}\;
	\exp\left[\;
			\log P\!\left(\,S=s\,\right)
			\,+\,
			\overset{T}{\underset{t=1}{\sum}}\;
			\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
			\,+\,
			\overset{s-1}{\underset{t=1}{\sum}}\;
			\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{e}\right.\,\right)
			\,-\,
			\overset{s-1}{\underset{t=1}{\sum}}\;
			\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
		\,\right]
	\right\}
\end{eqnarray*}
\end{proposition}
\proof
First, note that the marginal probability \,$P(D,R_{e},R_{l})$\, can be factored as follows:
\begin{eqnarray*}
P\!\left(\,D,R_{e},R_{l}\,\right)
&=&
	{\color{red}P\!\left(\,D \;\vert\, R_{e},R_{l}\,\right)}
	\cdot
	P\!\left(\,R_{e},R_{l}\,\right)
\;\; = \;\;
%& = &
%	\overset{T}{\underset{s=1}{\sum}}\;
%	P\!\left(\,D,S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\,\right)
%\;\; = \;\;
	{\color{red}
	\overset{T}{\underset{s=1}{\sum}}\;
	P\!\left(\,\left.D,S\overset{{\color{white}1}}{=}s \;\right\vert R_{e},R_{l}\,\right)}
	\cdot
	P\!\left(\,R_{e},R_{l}\,\right)
\\
& = &
	P\!\left(\,R_{e}\,\right)
	\cdot
	P\!\left(\,R_{l}\,\right)
	\;\cdot\;
	\overset{T}{\underset{s=1}{\sum}}\;\,
	P\!\left(\, D \;\left\vert\;S\overset{{\color{white}1}}{=}s,R_{e},R_{l} \right.\,\right)
	\cdot
	P\!\left(\,\left.S\overset{{\color{white}1}}{=}s\;\right\vert\,R_{e},R_{l}\,\right)
%\\
%& = &
%	P\!\left(\,R_{e}\,\right)
%	\cdot
%	P\!\left(\,R_{l}\,\right)
%	\,\times\,
%	\overset{T}{\underset{s=1}{\sum}}
%	\left(\,
%		\overset{T}{\underset{t=1}{\prod}}\;
%		P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
%		\right)
%	\cdot
%	P\!\left(\,S=s \;\vert\,R_{e},R_{l}\,\right)
\\
& = &
	P\!\left(\,R_{e}\,\right)
	\cdot
	P\!\left(\,R_{l}\,\right)
	\,\times\,
	{\color{red}
	\overset{T}{\underset{s=1}{\sum}}
		\left(\,
			\overset{T}{\underset{t=1}{\prod}}\;
			P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
			\right)
		\cdot
		P\!\left(\,S=s\,\right)
	}
\end{eqnarray*}
%Hence,
%\begin{eqnarray*}
%\log\,P\!\left(\,D,R_{e},R_{l}\,\right)
%& = &
%	\log P\!\left(\,R_{e}\,\right)
%	\; + \;
%	\log P\!\left(\,R_{l}\,\right)
%	\; + \;
%	\log\left(\;
%	\overset{T}{\underset{s=1}{\sum}}
%		\left(\,
%			\overset{T}{\underset{t=1}{\prod}}\;
%			P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
%			\right)
%		\cdot
%		P\!\left(\,S=s\,\right)
%	\,\right)
%\end{eqnarray*}
In particular, we see that
\begin{eqnarray*}
\log P\!\left(\,D \;\vert\, R_{e},R_{l}\,\right)
&=&
	\log\left\{\;\,
		\overset{T}{\underset{s=1}{\sum}}
		\left(\,
			\overset{T}{\underset{t=1}{\prod}}\;
			P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
			\right)
		\cdot
		P\!\left(\,S=s\,\right)
		\,\right\}
\\
& = &
	\log\left\{\;\,
	\overset{T}{\underset{s=1}{\sum}}\;
	\exp\,\circ\,\log\left[\,
		\left(\,
			\overset{T}{\underset{t=1}{\prod}}\;
			P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
			\right)
		\cdot
		P\!\left(\,S=s\,\right)
		\;\right]
	\,\right\}
%\\
%& = &
%	\log\left\{\;\,
%	\overset{T}{\underset{s=1}{\sum}}\;
%	\exp\left[\;
%		\log\left(\,
%			\overset{T}{\underset{t=1}{\prod}}\;
%			P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
%			\right)
%		\, + \,
%		\log P\!\left(\,S=s\,\right)
%		\right]
%	\,\right\}
\\
& = &
	\log\left\{\;\,
	\overset{T}{\underset{s=1}{\sum}}\;
	\exp\left[\;\log P\!\left(\,S=s\,\right)
			\, + \,
			\overset{T}{\underset{t=1}{\sum}}\,
				\log P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
		\,\right]
	\,\right\}
\end{eqnarray*}
Next, observe that:
\begin{eqnarray*}
&&
	\overset{T}{\underset{t=1}{\sum}}\;
	\log P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
\;\; = \;\;
	\overset{s-1}{\underset{t=1}{\sum}}\;
	\log P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
	\; + \;
	\overset{T}{\underset{t=s}{\sum}}\;
	\log P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
\\
&=&
	\overset{s-1}{\underset{t=1}{\sum}}\;
	\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{e}\right.\,\right)
	\; + \;
	\overset{T}{\underset{t=s}{\sum}}
	\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
\\
&=&
	{\color{white}+}\;\,
	\overset{s-1}{\underset{t=1}{\sum}}\;
	\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{e}\right.\,\right)
	\; + \;
	\overset{T}{\underset{t=s}{\sum}}\;
	\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
\\
&&
	{\color{blue}
	+\;\,
	\overset{s-1}{\underset{t=1}{\sum}}\;
	\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
	\; - \;
	\overset{s-1}{\underset{t=1}{\sum}}\;
	\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
	}
%\\
%&=&
%	\overset{s-1}{\underset{t=1}{\sum}}\;
%	\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{e}\right.\,\right)
%	\;+\;
%	\overset{T}{\underset{t=1}{\sum}}\;
%	\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
%		\;-\;\,
%		\overset{s-1}{\underset{t=1}{\sum}}\;
%		\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
\\
&=&
	\overset{T}{\underset{t=1}{\sum}}\;
	\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
	\;+\;
	\overset{s-1}{\underset{t=1}{\sum}}\;
	\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{e}\right.\,\right)
		\;-\;\,
		\overset{s-1}{\underset{t=1}{\sum}}\;
		\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
\end{eqnarray*}
Hence, we may now conclude:
\begin{eqnarray*}
&&
	\log P\!\left(\,D \;\vert\, R_{e},R_{l}\,\right)
\;\; = \;\;
	\log\left\{\;\,
	\overset{T}{\underset{s=1}{\sum}}\,
		\left(\,
			\overset{T}{\underset{t=1}{\prod}}\;
			P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
			\right)
		\cdot
		P\!\left(\,S=s\,\right)
	\,\right\}
\\
& = &
	\log\left\{\;
	\overset{T}{\underset{s=1}{\sum}}\;
	\exp\left[\;
		\log P\!\left(\,S=s\,\right)
		\, + \,
		\overset{T}{\underset{t=1}{\sum}}\,
		\log P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
		\,\right]
	\,\right\}
\\
&=&
	\log\left\{\;
	\overset{T}{\underset{s=1}{\sum}}\;
	\exp\left[\;
			\log P\!\left(\,S=s\,\right)
			\,+\,
			\overset{T}{\underset{t=1}{\sum}}\;
			\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
			\,+\,
			\overset{s-1}{\underset{t=1}{\sum}}\;
			\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{e}\right.\,\right)
			\,-\,
			\overset{s-1}{\underset{t=1}{\sum}}\;
			\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
		\,\right]
	\right\}
%\\
%&=&
%	\texttt{log\_sum\_exp}
%	\left[\;
%		\log P\!\left(\,S=s\,\right)
%		\,+\,
%		\overset{T}{\underset{t=1}{\sum}}\;
%		\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
%		\,+\,
%		\overset{s-1}{\underset{t=1}{\sum}}\;
%		\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{e}\right.\,\right)
%		\,-\,
%		\overset{s-1}{\underset{t=1}{\sum}}\;
%		\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
%		\,\right]
\end{eqnarray*}
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\begin{remark}
\mbox{}
\vskip 0.2cm
\noindent
The ``straightforward'' implementation of \,$P\!\left(\,D\,\vert\,R_{e},R_{l}\,\right)$\,
in \,$\textnormal{\texttt{Stan}}$\, based on the expression:
\begin{eqnarray*}
\underset{{\color{white}}}{\log P\!\left(\,D \;\vert\, R_{e},R_{l}\,\right)}
\;\; = \;\;
	\log\left\{\;
	\overset{T}{\underset{s=1}{\sum}}\;
	\exp\left[\;
		\log P\!\left(\,S=s\,\right)
		\, + \,
		\overset{T}{\underset{t=1}{\sum}}\,
		\log P\!\left(\,D_{t} \,\left\vert\; S\overset{{\color{white}1}}{=}s,R_{e},R_{l}\right.\,\right)
		\,\right]
	\,\right\}
\end{eqnarray*}
involves a doubly nested loop, and hence has $O(T^{\,2})$ complexity.
However, thanks to the availability of the function
\,$\textnormal{\texttt{log\_exp\_sum}}$\, in \,$\textnormal{\texttt{Stan}}$,
the equivalent expression
\begin{eqnarray*}
&&
	\underset{{\color{white}}}{\log P\!\left(\,D \;\vert\, R_{e},R_{l}\,\right)}
\\
&=&
	\log\left\{\;
	\overset{T}{\underset{s=1}{\sum}}\;
	\exp\left[\;
			\log P\!\left(\,S=s\,\right)
			\,+\,
			\overset{T}{\underset{t=1}{\sum}}\;
			\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
			\,+\,
			\overset{s-1}{\underset{t=1}{\sum}}\;
			\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{e}\right.\,\right)
			\,-\,
			\overset{s-1}{\underset{t=1}{\sum}}\;
			\log\textnormal{Poisson}\!\left(\,D_{t} \,\left\vert\; R_{l}\right.\,\right)
		\,\right]
	\right\}
\end{eqnarray*}
can be implemented with $O(T)$ complexity in \,$\textnormal{\texttt{Stan}}$,
which will be substantially more efficient in practice, especially when the number \,$T$\, of time points is large.
For more details, see
\begin{center}
$\textnormal{\texttt{https://mc-stan.org/docs/2\_23/stan-users-guide/change-point-section.html}}$
\end{center}
\end{remark}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
